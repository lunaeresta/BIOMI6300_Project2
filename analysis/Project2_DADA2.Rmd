---
title: "DADA2 Workflow for BIOMI6300 Project 2"
author: "Luna Eresta Jaya"
date: "2023-04-26"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Loading packages
```{r load}
# Set working directory
setwd("/workdir/lej52/BIOMI6300_Project2_Amplicon_Analysis")

# Load packman packages
# install.packages("pacman")
# Download Software 
pacman::p_load(dada2, tidyverse, patchwork, phyloseq, Biostrings, install = FALSE)
# Ensure correct package
packageVersion("dada2")

# Load in the functions file from code directory
source("/local/workdir/lej52/BIOMI6300_Project2_Amplicon_Analysis/code/functions.R")
```

# Set the path to the seq files
```{r}
# Set path to the gzipped files
path <- "data/sequencing_3"
path

# What files do we have?
list.files(path)

# Use 4 samples first to test workflow
samples <- c("JD-11", "JD-217", "JD-111", "JD-110")
```

# Load in Forward and Reverse reads and assess the quality
```{r}
# Load reads
# Create variable for the forward and the reverse reads

# Forward read variable
forward_reads <- sort(list.files(path, pattern="_1.fastq",
                      full.names=TRUE))

# Reverse read variable
reverse_reads <- sort(list.files(path, pattern="_2.fastq",
                      full.names=TRUE))

# 3. Place filtered files into filtered/subdirectory
# Create a variable holding file names for the Forward and Reverse filtered reads
filtered_forward_reads <- file.path(path, "filtered", paste0(samples, "_R1_filtered.fastq.gz"))
filtered_reverse_reads <- file.path(path, "filtered", paste0(samples, "_R2_filtered.fastq.gz"))

# Show the quality of each base on the reads of first 4 samples
forwardQual4_plot <- plotQualityProfile(forward_reads[1:4])
reverseQual4_plot <- plotQualityProfile(reverse_reads[1:4])

# Plot forward and reverse 4 quality plots together
forwardQual4_plot+reverseQual4_plot
```

# Filtering and trimming
```{r}
filtered_out <- filterAndTrim(forward_reads, filtered_forward_reads,
                              reverse_reads, filtered_reverse_reads,
                              truncLen = c(100, 100), trimLeft = c(20,20),
                              maxN = 0, maxEE = c(1,1), truncQ = 2,
                              rm.phix = TRUE, compress = TRUE,
                              multithread = TRUE)

# Use figaro by Zymo-Research (on github) to trim auotomatically


# Show the quality of each base on the reads of first sample
filtered_forwardQual4_plot <- plotQualityProfile(filtered_forward_reads[1:4])
filtered_reverseQual4_plot <- plotQualityProfile(filtered_reverse_reads[1:4])
filtered_forwardQual4_plot+filtered_reverseQual4_plot

```

# Generate an error model
```{r}
# Learn errors
err_forward_reads <- learnErrors(filtered_forward_reads, multithread = TRUE)
err_reverse_reads <- learnErrors(filtered_reverse_reads, multithread = TRUE)

# Plot the errors
plotErrors(err_forward_reads, nominalQ = TRUE)
plotErrors(err_reverse_reads, nominalQ = TRUE)
```

# Inferring ASVs on the forward and reverse sequences
```{r infer-ASVs}
# run dada2 on the forward seqs
dada_forward <- dada(filtered_forward_reads, err = err_forward_reads, multithread = TRUE)

# run dada2 on the reverse sequences
dada_reverse <- dada(filtered_reverse_reads, err = err_reverse_reads, multithread = TRUE)
dada_reverse[1]
```

# Merge forward and reverse ASVs
```{r merge-FandR-ASVs}
# Merge and forward ASVs and the reverse ASVs
merged_amplicons <- mergePairs(dada_forward, filtered_forward_reads,
                              dada_reverse, filtered_reverse_reads,
                              verbose = TRUE)

# Evaluate the output
merged_amplicons
typeof(merged_amplicons)
length(merged_amplicons)
names(merged_amplicons)

merged_amplicons[1]
```

# Generate a count table
```{r gen-countTable-seqTab}
seqtab <- makeSequenceTable(merged_amplicons)
class(seqtab)
typeof(seqtab)
dim(seqtab)
View(seqtab)

# Inspect the distribution of sequence lengths of all ASVs in the dataset
table(nchar(getSequences(seqtab)))
# why are there samples with more or less than 214 base pairs?
```

I have `r ncol(seqtab)` ASVs in the dataset!

# Check & Remove for Chimeras (Bimeras)
```{r}
# Identify and remove chimeras
seqtab_nochim <- removeBimeraDenovo(seqtab, verbose=TRUE)

# What proportion of counts were removed?
chim_check <- sum(seqtab_nochim)/sum(seqtab) # 0.9725445
frac_removed <- (1-chim_check)*100 #percent
frac_removed
#11.73% percent was removed based on 4 sequencing data files
```

Chimeras represented `r frac_removed` percent of the data.

# Track the sequences through the pipeline
```{r}
# Create a little function to identify number seqs
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs
track <- cbind(filtered_out,
               sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_amplicons, getN),
               rowSums(seqtab_nochim))
head(track)

# Change column names
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- samples
head(track)

# Generate a plot to track the reads through our DADA2 pipeline
track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var= "names") %>%
  pivot_longer(input:nochim, names_to = "read_type", values_to = "num_reads") %>%
  make_MA_metadata() %>%
  mutate(read_type = fct_relevel(read_type, 
                                 "input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y=num_reads, fill = read_type)) +
  facet_grid(~fraction) +
  geom_line(aes(group = names), color = "grey") +
  geom_point(shape = 21, size = 3, alpha = 0.8) +
  scale_fill_brewer(palette = "Spectral") +
  theme_bw() +
  labs(x = "Filtering Step", y = "Number of Sequences") +
  theme(legend.position = "bottom", legend.title = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# First, let's source the colors_and_shapes.R
# This file is in /workdir/in_class_data/colors_and_shapes.R
source("code/colors_and_shapes.R")


# Plot the percent reads retained 
# track %>%
#   as.data.frame() %>%
#   mutate(percent_reads_retained = round((nochim/input)*100, digits = 2)) %>%
#   rownames_to_column(var = "names") %>% # As input to make_MA_metadata
#   make_MA_metadata() %>%
#   # Make the plot! 
#   ggplot(aes(x = fraction, y = percent_reads_retained, fill = fraction)) + 
#   geom_jitter(shape = 21, size = 3, alpha = 0.8) + 
#   geom_boxplot(alpha = 0.4, outlier.shape = NA) + 
#   # scale_fill_manual(values = fraction_colors) + 
#   theme_bw() + 
#   labs(y = "Percent Sequences Retained by DADA2") +
#   theme(axis.title.x = element_blank())
```

# Assign taxonomy
```{r assign-tax}
# The next line took 2 mins to run
taxa <- assignTaxonomy(seqtab_nochim, "/workdir/in_class_data/taxonomy/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)

# the next line took 3 minutes 
taxa <- addSpecies(taxa, "/workdir/in_class_data/taxonomy/silva_species_assignment_v138.1.fa.gz")

# Inspect the taxonomy 
taxa_print <- taxa # Removing sequence rownames for display only
rownames(taxa_print) <- NULL
View(taxa_print)
```


NOTE:
THERE WAS NO MOCK COMMUNITY IN THIS ANALYSIS, HENCE THE CODE CHUNK FOR MEASURING MOCK COMMUNITY DETECTION ACCURACY WAS REMOVED.


